<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>PointRend | Fly-Pluche</title><meta name="description" content="§摘要我们提出了一种高效、高质量的目标和场景图像分割新方法。通过类比经典的计算机图形学方法高效渲染像素标记任务中面临的过采样和欠采样挑战，我们发展了一个独特的视角，将图像分割作为一个渲染问题。从这个优势出发，我们提出了PointRend(基于点的渲染)神经网络模块:该模块基于迭代细分算法，在自适应选择的位置执行基于点的分割预测。PointRend可以通过在现有的最先进的模型之上构建，灵活地应用于实"><meta name="keywords" content="点渲染"><meta name="author" content="Fly-Pluche"><meta name="copyright" content="Fly-Pluche"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://fly-pluche.github.io/posts/PointRend/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><meta property="og:type" content="article"><meta property="og:title" content="PointRend"><meta property="og:url" content="https://fly-pluche.github.io/posts/PointRend/"><meta property="og:site_name" content="Fly-Pluche"><meta property="og:description" content="§摘要我们提出了一种高效、高质量的目标和场景图像分割新方法。通过类比经典的计算机图形学方法高效渲染像素标记任务中面临的过采样和欠采样挑战，我们发展了一个独特的视角，将图像分割作为一个渲染问题。从这个优势出发，我们提出了PointRend(基于点的渲染)神经网络模块:该模块基于迭代细分算法，在自适应选择的位置执行基于点的分割预测。PointRend可以通过在现有的最先进的模型之上构建，灵活地应用于实"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/HCLonely/hclonely.github.io/img/Butterfly/007.webp"><meta property="article:published_time" content="2021-05-17T10:22:44.000Z"><meta property="article:modified_time" content="2021-05-26T09:01:51.410Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="prev" title="Math" href="https://fly-pluche.github.io/posts/Math/"><link rel="next" title="图像高低频" href="https://fly-pluche.github.io/posts/Image_high_and_low_frequency/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: false,
  copyright: {"languages":{"author":"作者: Fly-Pluche","link":"链接: ","source":"来源: Fly-Pluche","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: true,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: true    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-05-26 17:01:51'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@master/Hexo/css/flink.min.css"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/Fly_Pluche.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">13</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">10</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">14</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> 媒体</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/bangumis/"><i class="fa-fw fab fa-youtube"></i><span> 番剧</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书单</span></a></li><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/box/"><i class="fa-fw fab fa-xbox"></i><span> 聚宝盒</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><i class="fa-fw far fa-comment"></i><span> 微语</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/gallery/"><i class="fa-fw far fa-image"></i><span> 相册</span></a></li><li><a class="site-page" href="/home/"><i class="fa-fw fab fa-phoenix-framework"></i><span> 主页</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/contact/"><i class="fa-fw far fa-comments"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#§摘要"><span class="toc-number">1.</span> <span class="toc-text">§摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#§壹、-现存的问题"><span class="toc-number">2.</span> <span class="toc-text">§壹、 现存的问题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#§贰、-解决的问题"><span class="toc-number">3.</span> <span class="toc-text">§贰、 解决的问题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#§叁、-创新点："><span class="toc-number">4.</span> <span class="toc-text">§叁、 创新点：</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#§肆、-思想概括"><span class="toc-number">5.</span> <span class="toc-text">§肆、 思想概括</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#思想启发（相关工作）"><span class="toc-number">5.1.</span> <span class="toc-text">思想启发（相关工作）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#§伍、-PointRend优点"><span class="toc-number">6.</span> <span class="toc-text">§伍、 PointRend优点</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#通用性"><span class="toc-number">6.1.</span> <span class="toc-text">通用性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#高效性"><span class="toc-number">6.2.</span> <span class="toc-text">高效性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#适用性"><span class="toc-number">6.3.</span> <span class="toc-text">适用性</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#§陆、Architecture架构"><span class="toc-number">7.</span> <span class="toc-text">§陆、Architecture架构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#§柒、-PointRend"><span class="toc-number">8.</span> <span class="toc-text">§柒、 PointRend</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#7-1-Point-Selection-for-Inference-and-Training（点选择的推理和训练）"><span class="toc-number">8.1.</span> <span class="toc-text">7.1 Point Selection for Inference and Training（点选择的推理和训练）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#推理"><span class="toc-number">8.1.1.</span> <span class="toc-text">推理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#训练"><span class="toc-number">8.1.2.</span> <span class="toc-text">训练</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-2-Point-wise-Representation"><span class="toc-number">8.2.</span> <span class="toc-text">7.2 Point-wise Representation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#细粒度特性（包含相对低级的信息）"><span class="toc-number">8.2.1.</span> <span class="toc-text">细粒度特性（包含相对低级的信息）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#粗预测功能"><span class="toc-number">8.2.2.</span> <span class="toc-text">粗预测功能</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Point-Head"><span class="toc-number">8.3.</span> <span class="toc-text">Point Head</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#捌、网络过程（一些细节）"><span class="toc-number">9.</span> <span class="toc-text">捌、网络过程（一些细节）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1、Prepare-input-image"><span class="toc-number">9.0.1.</span> <span class="toc-text">1、Prepare input image.</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2、Get-bounding-box-predictions-first-to-simplify-the-code"><span class="toc-number">9.0.2.</span> <span class="toc-text">2、Get bounding box predictions first to simplify the code.</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3、Run-backbone"><span class="toc-number">9.0.3.</span> <span class="toc-text">3、Run backbone.</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4、Given-the-bounding-boxes-run-coarse-mask-prediction-head-（得到粗预测）"><span class="toc-number">9.0.4.</span> <span class="toc-text">4、Given the bounding boxes, run coarse mask prediction head.（得到粗预测）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5、随机生成KN（K-gt-1-个点坐标，在其中选出N个不确定点。"><span class="toc-number">9.0.5.</span> <span class="toc-text">5、随机生成KN（K&gt;1)个点坐标，在其中选出N个不确定点。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#关于得到不确定点的细节"><span class="toc-number">9.1.</span> <span class="toc-text">关于得到不确定点的细节</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#①建立logit模型"><span class="toc-number">9.1.1.</span> <span class="toc-text">①建立logit模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#②对建立logit模型以及搞一些奇奇怪怪的操作（取绝对值跟负号）的理解"><span class="toc-number">9.1.2.</span> <span class="toc-text">②对建立logit模型以及搞一些奇奇怪怪的操作（取绝对值跟负号）的理解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#③-不确定点-不确定点-随机点"><span class="toc-number">9.1.3.</span> <span class="toc-text">③ 不确定点&#x3D;不确定点+随机点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据集"><span class="toc-number">9.2.</span> <span class="toc-text">数据集</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#小问号Q-amp-A"><span class="toc-number">10.</span> <span class="toc-text">小问号Q&amp;A</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#①Q-为什么要在随机选KN个点，然后在其中选βN个点？"><span class="toc-number">10.1.</span> <span class="toc-text">①Q:为什么要在随机选KN个点，然后在其中选βN个点？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#A1：为了实现高性能，每个区域只采样少量的点，并采用温和的偏置采样策略（即下图中的C），使系统在训练时更有效率。"><span class="toc-number">10.2.</span> <span class="toc-text">A1：为了实现高性能，每个区域只采样少量的点，并采用温和的偏置采样策略（即下图中的C），使系统在训练时更有效率。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#A2：从3D图像处理方法进行借鉴"><span class="toc-number">10.3.</span> <span class="toc-text">A2：从3D图像处理方法进行借鉴</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-number">11.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div><div id="body-wrap"><div id="web_bg" data-type="photo"></div><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/gh/HCLonely/hclonely.github.io/img/Butterfly/007.webp)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Fly-Pluche</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> 媒体</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/bangumis/"><i class="fa-fw fab fa-youtube"></i><span> 番剧</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书单</span></a></li><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/box/"><i class="fa-fw fab fa-xbox"></i><span> 聚宝盒</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><i class="fa-fw far fa-comment"></i><span> 微语</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/gallery/"><i class="fa-fw far fa-image"></i><span> 相册</span></a></li><li><a class="site-page" href="/home/"><i class="fa-fw fab fa-phoenix-framework"></i><span> 主页</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/contact/"><i class="fa-fw far fa-comments"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">PointRend</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2021-05-17 18:22:44"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2021-05-17</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2021-05-26 17:01:51"><i class="fas fa-history fa-fw"></i> 更新于 2021-05-26</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/Paper/">Paper</a><i class="fas fa-angle-right post-meta__separator"></i><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/Paper/cv/">cv</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="§摘要"><a href="#§摘要" class="headerlink" title="§摘要"></a>§摘要</h1><p>我们提出了一种高效、高质量的目标和场景图像分割新方法。通过类比经典的计算机图形学方法高效渲染像素标记任务中面临的过采样和欠采样挑战，我们发展了一个独特的视角，将图像分割作为一个渲染问题。从这个优势出发，我们提出了PointRend(基于点的渲染)神经网络模块:该模块基于迭代细分算法，在自适应选择的位置执行基于点的分割预测。PointRend可以通过在现有的最先进的模型之上构建，灵活地应用于实例分割和语义分割任务。虽然很多具体的实现都是可能的，但是我们展示了一个简单的设计已经获得了很好的结果。定性地说，PointRend在以前的方法光滑过的区域中输出清晰的对象边界。从数量上讲，无论是实例还是语义分割，PointRend在COCO和cityscape上都有显著的收益。与现有方法相比，PointRend的效率使得输出分辨率在内存或计算方面更切合实际。</p>
<p><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517132130.png" alt="image-20210517132127397"></p>
<p>Paper：<a href="https://arxiv.org/pdf/1912.08193.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1912.08193.pdf</a></p>
<p>Code：<a href="https://github.com/facebookresearch/detectron2/blob/master/projects/PointRend" target="_blank" rel="noopener">https://github.com/facebookresearch/detectron2/blob/master/projects/PointRend</a></p>
<h1 id="§壹、-现存的问题"><a href="#§壹、-现存的问题" class="headerlink" title="§壹、 现存的问题"></a>§壹、 现存的问题</h1><p>一个规则的网格将会不必要地过度采样光滑的区域，同时对对象的边界采样不足。导致在平滑区域中计算过多。</p>
<h1 id="§贰、-解决的问题"><a href="#§贰、-解决的问题" class="headerlink" title="§贰、 解决的问题"></a>§贰、 解决的问题</h1><p>提出了一种高效、高质量的目标和场景图像分割新方法，以要解决在实例分割任务中边缘不够精细的问题。</p>
<h1 id="§叁、-创新点："><a href="#§叁、-创新点：" class="headerlink" title="§叁、 创新点："></a>§叁、 创新点：</h1><p>将运算的精力集中到预测模糊点！！</p>
<p>PointRend并没有对输出网格上的所有点进行过多的预测，而是只对精心选择的点进行预测。<br>它以迭代的方式细化从目标轮廓区域选择的点的分割预测，将优化物体边缘的图像分割，适用于对难以分割的物体边缘，或是对边缘分割精度要求很高的场景下。</p>
<h1 id="§肆、-思想概括"><a href="#§肆、-思想概括" class="headerlink" title="§肆、 思想概括"></a>§肆、 思想概括</h1><p>本文的中心思想是将图像分割视为一个渲染问题，并采用计算机图形学的经典思想高效地“渲染”高质量标签地图(见图1，左下)。我们将这种计算思想封装在一个新的神经网络模块中，称为PointRend，该模块使用细分策略自适应地选择一个非一致的点集来计算标签。</p>
<h2 id="思想启发（相关工作）"><a href="#思想启发（相关工作）" class="headerlink" title="思想启发（相关工作）"></a>思想启发（相关工作）</h2><p>对于之前的分割算法，可以看成是：</p>
<p>1、首先使用宽、高两个维度的坐标构成的均匀网格对图片进行划分。每个格子（每个坐标点，或者每个像素点）相当于一个采样点；<br>2、然后使用分割算法，对每个采样点进行分类。<br>一张任意图片里面，有低频、高频区域。在图像分割问题里面，两类区域有如下不同：</p>
<p>1、对于图片中低频区域（low-frequency、smooth-area），里面的点，大概率属于同一个物体，直觉上，没必要使用太多的采样点。如果使用的点太多，相当于过采样（oversample）；</p>
<p>2、对于图片中高频区域（high-frequency），里面的点，大概率靠近物体边界。直觉上，如果这些区域的采样点太稀疏，最终会导致分割出来的物体边界过于平滑，不太真实，相当于欠采样（undersample）；相反，如果采样点越多，分割出来的物体边界应该会更精细（sharp bounder）、真实。</p>
<p>用均匀网格划分图片采样的方式，对于低频区域来说，可能会过采样，浪费一些计算资源；对于高频区域来说，可能会欠采样，不能够得出精细的结果。</p>
<p>按照以上分析，即可得出优化分割算法的一个重要思路：<strong>优化采样方式</strong>。</p>
<p>类似的采样问题，在graphics图像渲染领域，已经研究了很久。以图像渲染为例，一个常见的处理方式是：</p>
<p>1、首先使用某种采样方式进行采样。采样是不规则的，比如，高频区域多采样、低频区域少采样。然后计算每个采样点的像素值。</p>
<p>2、然后通过渲染（rendering），将位置不规则的采样点的像素值，映射（例如插值）到位置规则的grid里面。 </p>
<p>借鉴graphics里面渲染的思路，论文将分割问题看作一个类似的渲染问题来处理：</p>
<p>1、先通过一种“合理”的采样方式进行非均匀采样，计算出每个采样点的分割结果；</p>
<p>2、然后再将结果映射到规则的grid里面，类比rendering的过程。<br>论文将此方法称为：PointRend。</p>
<h1 id="§伍、-PointRend优点"><a href="#§伍、-PointRend优点" class="headerlink" title="§伍、 PointRend优点"></a>§伍、 PointRend优点</h1><h2 id="通用性"><a href="#通用性" class="headerlink" title="通用性"></a>通用性</h2><p>PointRend可以被合并到流行的元架构中，用于实例分割(例如Mask R-CNN[19])和语义分割中。</p>
<h2 id="高效性"><a href="#高效性" class="headerlink" title="高效性"></a>高效性</h2><p>它的细分策略有效地计算高分辨率分割地图，使用的浮点运算比直接密集计算少一个数量级。</p>
<h2 id="适用性"><a href="#适用性" class="headerlink" title="适用性"></a>适用性</h2><p>适用于对难以分割的物体边缘，或是对边缘分割精度要求很高的场景下。<br>效果图：<br><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517132519.png" alt="image-20210517132150068"></p>
<h1 id="§陆、Architecture架构"><a href="#§陆、Architecture架构" class="headerlink" title="§陆、Architecture架构"></a>§陆、Architecture架构</h1><p>我们实验的网络的主体框架是带有 ResNet-50 [20] + FPN [28] backbone的Mask R-CNN。</p>
<p>Mask R-CNN中的默认的mask head 是一个逐区域的FCN。</p>
<p>MLP是的输入是来自主干CNN的细粒度特征映射和粗预测。粗预测使MLP能够在由两个或多个box包含的单个点上做出不同的预测。细分掩模绘制算法，可以迭代细化预测掩模的不确定区域。</p>
<p><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517132205.png" alt="image-20210517132204341"></p>
<p>一个标准的网络分割(红色实箭头)获取输入图像，并使用一个轻量级的分割为每个检测到的对象(红色框)产生一个粗糙的(例如7×7)掩模预测。<strong>为了细化粗掩模</strong>，PointRend选择难以预测的点(红点/边界)，并使用较小的MLP对每个点独立进行预测，把网路的重心放在难以预测的地方（详见6.1的迭代上采样）。最后再把粗预测与细预测的结果融合（个人理解）输入MLP，MLP使用插值特征计算。</p>
<p>MLP使用在这些点(红色虚线箭头)上计算的插值特征，这些点来自(1)主干CNN的细粒度特征映射和(2)来自粗预测掩码。粗掩码特性使MLP能够在由两个或多个盒子包含的单个点上做出不同的预测。本文提出的细分掩模绘制算法(图4和§3.1)利用此过程迭代细化预测掩模的不确定区域。</p>
<h1 id="§柒、-PointRend"><a href="#§柒、-PointRend" class="headerlink" title="§柒、 PointRend"></a>§柒、 PointRend</h1><p>PointRend模块主要由三个部分组成:<br>（i）A point selection strategy （点选择策略）：</p>
<p>选择少量真值点执行预测，避免对高分辨率输出网格中的所有像素进行过度计算；点选择能够有效节省算力，避免对高分辨率输出网格中的所有像素进行过度计算。<br>（ii） 级联细粒度和粗略预测特征</p>
<p>粗预测：多次迭代计算不确定不确定点，从小的feature map 双线性插值为大的feature map,</p>
<p>细粒度：细粒度特征图具有原图尺寸。</p>
<p>如上图（Fig.3）所示。</p>
<p><strong>细粒度特征具有物体的细节信息。粗预测特征提供更多的上下文信息，同时表达语义类别。最后拼接作为每个点的最终特征表示。</strong></p>
<p>（iii）point head：</p>
<p>一个经过训练的小型神经网络，从这种逐点特征表示中独立地预测每个点的标签。</p>
<p> 下面我们就对他们挨个进行介绍：</p>
<h2 id="7-1-Point-Selection-for-Inference-and-Training（点选择的推理和训练）"><a href="#7-1-Point-Selection-for-Inference-and-Training（点选择的推理和训练）" class="headerlink" title="7.1 Point Selection for Inference and Training（点选择的推理和训练）"></a>7.1 Point Selection for Inference and Training（点选择的推理和训练）</h2><h3 id="推理"><a href="#推理" class="headerlink" title="推理"></a>推理</h3><p> 我们的推理选择策略是受到计算机图形学中经典的自适应细分技术[48]的启发。</p>
<p>该技术通过只注重于高概率相邻像素不同的地方来渲染高分辨率的图像（例如，通过光线追踪）; 对于所有其他位置的值都是通过插值已经计算出的输出值(从一个粗糙的网格开始)获得的。</p>
<p> 对于每个区域，我们以一种从粗到细的方式迭代地“渲染”输出蒙版。最粗糙的水平预测是在一个规则的网格上的点(例如，通过使用一个标准的粗分割预测头)。具体内容如下：</p>
<p>最开始输入粗预测的是最原始的最小分辨率的feature map。</p>
<p>1.其进行预测。</p>
<p>2.对预测结果进行双线性插值进行上采样（对应于下图中间的28x28格子）。它是通过对7x7的格子使用双线性插值进行上采样后的结果。</p>
<p>3.然后在上采样的结果中选择Top βN 个 不确定的点。所谓最不确定，是指分割的概率最接近0.5的点（为什么是0.5？，如果预测值为0.3这类比较小的数据，因为预测类的标签中没有背景，所以说明这这个像素可能是背景），这些点一般在边界不同物体的边界，难以判断前景与背景，label1与label2（对应于中间图里面有黑圈的位置）。</p>
<p>4.然后再对对N个不确定的点(红点)进行预测，在更精细的网格上恢复细节。</p>
<p>重复迭代1~4这个过程，直到达到所需的网格分辨率。</p>
<img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517132225.png" alt="image-20210517132222340" style="zoom:80%;" />

<img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210516214839.png" alt="image-20210511104949787" style="zoom:50%;" />

<img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210516220420.png" alt="image-20210511104957843" style="zoom:50%;" />

<img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517125310.png" alt="image-20210511105005337" style="zoom:50%;" />

<img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517125044.png" alt="image-20210511105012751" style="zoom:50%;" />

<p><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517125033.png" alt="image-20210511154406302"></p>
<p> 论文中的单次迭代图（这个图里的图片尺寸与上面的不一样）：</p>
<p> <img src= "/img/loading.gif" data-src="https://img-blog.csdnimg.cn/20210510100319597.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzUxMzAyNTY0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>在训练过程中，PointRend还需要选择点来构建逐点特征，用于point head。原则上，点选择策略可以类似于在推理中使用的细分策略。然而，细分引入的顺序步骤对用反向传播训练神经网络不太友好。相反，我们使用一种基于<strong>随机抽样的非迭代策略进行训练</strong>。</p>
<p>采样策略在feature map上选择随机的N个点进行训练。它的设计是为了使网络选择不确定的区域进行计算，同时保留一定程度的统一覆盖，一共三个原则：<br>(i)过生成:</p>
<p>我们从均匀分布中随机抽取KN（K&gt;1）个点作为候选点。<br>(ii)重要性抽样:</p>
<p>我们通过先插值所有kN点上的粗糙预测值，然后计算特定任务的不确定性估计数，选择KN中的βN(β∈[0,1])个点，作为需要关注的具有不确定性的粗预测点。<br>(iii)广域覆盖:</p>
<p>从从均匀分布采样（FIg.5 a））中选择(1−β)N个点。 </p>
<p>上述三个步骤可示意为下图（图5），在k和β变化的情况下（对于train和inference，N的值可以不同），得到了各点对不同的偏向。</p>
<p>在训练时，除了粗分割，预测和损失函数只在N采样点（βN+（1-βN））上计算，这比通过细分步骤更简单和高效。这种设计类似于Faster R-CNN系统[13]中RPN + Fast R-CNN的并行训练，其推理是顺序的。</p>
<p><img src= "/img/loading.gif" data-src="https://img-blog.csdnimg.cn/2021051015210544.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzUxMzAyNTY0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p> 上图展示了Fig.4中采样方式。论文指出，mildly biased采样在training过程中的效果最好。</p>
<p>biased采样，是指：向预测结果不确定的点“偏移“的采样方式。</p>
<h2 id="7-2-Point-wise-Representation"><a href="#7-2-Point-wise-Representation" class="headerlink" title="7.2 Point-wise Representation"></a>7.2 Point-wise Representation</h2><p>PointRend通过组合两种特性类型(细粒度和粗预测特性)，在选定的点上构造逐点的特性，下面将进行描述。</p>
<h3 id="细粒度特性（包含相对低级的信息）"><a href="#细粒度特性（包含相对低级的信息）" class="headerlink" title="细粒度特性（包含相对低级的信息）"></a>细粒度特性（包含相对低级的信息）</h3><p>使用例如ResNet这样的backbone CNN网络抽取出来的feature。</p>
<p>为了让PointRend渲染我们从CNN的feature maps中提取的特征向量精细分割细节。</p>
<p>为了让PointRend渲染精细分割细节，我们从CNN特征地图提取特征矢量采样点。由于点是一个实值的二维坐标，我们按照标准实践[22,19,10]，在特征图上进行双线性插值去计算特征向量。特征可以从一个简单的特征映射中提取(例如，res2 in a ResNet)，它们也可以从多个特征映射(例如，res2到res5，或它们的特征金字塔[28]对等体)中提取，并按照超列方法[17]（Hypercolumns for object segmentation and fine-grained localization.）连接。</p>
<h3 id="粗预测功能"><a href="#粗预测功能" class="headerlink" title="粗预测功能"></a>粗预测功能</h3><p>网络计算出的一个粗略的分割结果。</p>
<p>细粒度特性支持解析细节，但在两个方面也存在缺陷。</p>
<p>①首先，它们不包含特定区域的信息，因此被两个实例的边界框重叠的同一点将具有相同的细粒度特征。然而，一点只能在一个实例前景。因此，对于实例分割任务，不同区域可能对同一点预测不同的标签，需要额外的区域特定信息。</p>
<p>②其次，根据细粒度特性所使用的特性映射，这些特性可能只包含相对低级的信息(例如，我们将在DeepLabV3中使用res2)。在这种情况下，具有更多上下文和语义信息的特性源可能会很有帮助。这个问题同时影响实例和语义分割。</p>
<p>基于这些考虑，第二种特征类型是来自网络的粗分割预测，即区域(盒)中每一点的k维向量表示一个k类预测。根据设计，粗解析提供更更全面的上下文，而通道传递语义类。</p>
<h2 id="Point-Head"><a href="#Point-Head" class="headerlink" title="Point Head"></a>Point Head</h2><p>相当于一个MLP多层网络。把前两个步骤计算出每个特殊点的feature后，通过MLP，对每一个点的feature进行处理，得到一个新的预测结果。</p>
<p>对于每个选定点的逐点特征表示，PointRend使用简单的多层感知器(MLP)进行逐点分割预测。这个MLP跨所有点(和所有区域)共享权值，类似于图卷积[23]或PointNet[43]。由于MLP预测每个点的分段标签，它可以通过标准的特定任务分段损失(在论文中§4和§5中描述)来训练。</p>
<p><img src= "/img/loading.gif" data-src="https://img-blog.csdnimg.cn/20210510100354742.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzUxMzAyNTY0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h1 id="捌、网络过程（一些细节）"><a href="#捌、网络过程（一些细节）" class="headerlink" title="捌、网络过程（一些细节）"></a>捌、网络过程（一些细节）</h1><p><a href="https://colab.research.google.com/drive/1isGPL5h5_cKoPPhVL9XhMokRtHDvmMVL#scrollTo=-meq_L0xLhr0&uniqifier=2" target="_blank" rel="noopener">Colab:https://colab.research.google.com/drive/1isGPL5h5_cKoPPhVL9XhMokRtHDvmMVL#scrollTo=-meq_L0xLhr0&amp;uniqifier=2</a></p>
<h3 id="1、Prepare-input-image"><a href="#1、Prepare-input-image" class="headerlink" title="1、Prepare input image."></a>1、Prepare input image.</h3><h3 id="2、Get-bounding-box-predictions-first-to-simplify-the-code"><a href="#2、Get-bounding-box-predictions-first-to-simplify-the-code" class="headerlink" title="2、Get bounding box predictions first to simplify the code."></a>2、Get bounding box predictions first to simplify the code.</h3><h3 id="3、Run-backbone"><a href="#3、Run-backbone" class="headerlink" title="3、Run backbone."></a>3、Run backbone.</h3><h3 id="4、Given-the-bounding-boxes-run-coarse-mask-prediction-head-（得到粗预测）"><a href="#4、Given-the-bounding-boxes-run-coarse-mask-prediction-head-（得到粗预测）" class="headerlink" title="4、Given the bounding boxes, run coarse mask prediction head.（得到粗预测）"></a>4、Given the bounding boxes, run coarse mask prediction head.（得到粗预测）</h3><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517124911.png" alt="image-20210511100342099" style="zoom:50%;" />

<h3 id="5、随机生成KN（K-gt-1-个点坐标，在其中选出N个不确定点。"><a href="#5、随机生成KN（K-gt-1-个点坐标，在其中选出N个不确定点。" class="headerlink" title="5、随机生成KN（K&gt;1)个点坐标，在其中选出N个不确定点。"></a>5、随机生成KN（K&gt;1)个点坐标，在其中选出N个不确定点。</h3><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517124904.png" alt="image-20210511101258739" style="zoom: 50%;" />

<p>从KN中选N个点，这也是为什么这个飞机没有被红点连成封闭图形的原因。</p>
<img src= "/img/loading.gif" data-src="C:\Users\BlackFriday\AppData\Roaming\Typora\typora-user-images\image-20210514135949657.png" alt="image-20210514135949657" style="zoom:67%;" />

<h2 id="关于得到不确定点的细节"><a href="#关于得到不确定点的细节" class="headerlink" title="关于得到不确定点的细节"></a>关于得到不确定点的细节</h2><h3 id="①建立logit模型"><a href="#①建立logit模型" class="headerlink" title="①建立logit模型"></a>①建立logit模型</h3><p>我们先来科普一下这个模型</p>
<p><img src= "/img/loading.gif" data-src="https://img-blog.csdn.net/20180906155953727?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Jyb29rbmV3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p>
<p>Logit  is Log of odds.</p>
<p><img src= "/img/loading.gif" data-src="https://img-blog.csdn.net/20180906160003203?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Jyb29rbmV3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p>
<p>论文是把预测值输入这个预测模型，然后对这个结果取绝对值，然后加负号，然后取Top K  就是需要的不确定点。</p>
<h3 id="②对建立logit模型以及搞一些奇奇怪怪的操作（取绝对值跟负号）的理解"><a href="#②对建立logit模型以及搞一些奇奇怪怪的操作（取绝对值跟负号）的理解" class="headerlink" title="②对建立logit模型以及搞一些奇奇怪怪的操作（取绝对值跟负号）的理解"></a>②对建立logit模型以及搞一些奇奇怪怪的操作（取绝对值跟负号）的理解</h3><p>图片中某一行像素点进行预测，其最大可能的预测输出为：</p>
<p>[0,2，0.4，0.5 ，0.7，……] (这里我们着重注意0.2，之所以会出现0.2的概率，可能是因为这个是背景图，所以预测不到东西)</p>
<p>下图为对应的logit（纯搞笑手绘）：</p>
<p><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517124819.png" alt="image-20210512141533381"></p>
<p>取绝对值</p>
<p><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517124814.png" alt="image-20210512141551716"></p>
<p>取负数</p>
<p><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517124809.png" alt="image-20210512141637821"></p>
<p>最后再用torch.topk取前βK个为不确定点。</p>
<h3 id="③-不确定点-不确定点-随机点"><a href="#③-不确定点-不确定点-随机点" class="headerlink" title="③ 不确定点=不确定点+随机点"></a>③ 不确定点=不确定点+随机点</h3><p>最后用于计算的不确定点为：概率为0.5左右的不确定点+随机得到的点坐标</p>
<p><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517124730.png" alt="image-20210514133258003" style="zoom:33%;" /><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517124718.png" alt="image-20210514133313417" style="zoom:33%;" /></p>
<p>详细见柒.训练中的(iii)广域覆盖。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>我们使用两个标准的实例分割数据集:COCO[29]和Cityscapes。我们报告了标准掩模AP度量[29]，使用了COCO  3次运行的中位数和Cityscapes  5次运行的中位数(它有更高的方差)。COCO有80个具有实例级注释的类别。我们在train2017(约118k图像)上训练，并在val2017  (5k图像)上报告结果。正如[16]中提到的，<strong>COCO  ground-truth通常是粗糙的，数据集的AP可能不能完全反映掩模质量的改进</strong>。因此，我们用用LVIS[16]的80个COCO类别子集(用AP?表示)测量的AP来补充COCO结果。<strong>LVIS注释的质量显著提高</strong>。我们使用在COCO上训练过的相同模型，并使用LVIS评估API简单地针对更高质量的LVIS注释重新评估它们的预测。<strong>Cityscapes是一个以自我为中心的街景数据集与COCO  (1024×2048像素)相比，该图像具有更高的分辨率，具有更精细、更精确的地物真相实例分割</strong>。</p>
<h1 id="小问号Q-amp-A"><a href="#小问号Q-amp-A" class="headerlink" title="小问号Q&amp;A"></a>小问号Q&amp;A</h1><h2 id="①Q-为什么要在随机选KN个点，然后在其中选βN个点？"><a href="#①Q-为什么要在随机选KN个点，然后在其中选βN个点？" class="headerlink" title="①Q:为什么要在随机选KN个点，然后在其中选βN个点？"></a>①Q:为什么要在随机选KN个点，然后在其中选βN个点？</h2><p>为什么要在随机选KN个点，然后在其中选βN个点？为什么不直接在全部的像素点中选取一定比例的点作为不确定点呢？</p>
<h2 id="A1：为了实现高性能，每个区域只采样少量的点，并采用温和的偏置采样策略（即下图中的C），使系统在训练时更有效率。"><a href="#A1：为了实现高性能，每个区域只采样少量的点，并采用温和的偏置采样策略（即下图中的C），使系统在训练时更有效率。" class="headerlink" title="A1：为了实现高性能，每个区域只采样少量的点，并采用温和的偏置采样策略（即下图中的C），使系统在训练时更有效率。"></a>A1：为了实现高性能，每个区域只采样少量的点，并采用温和的偏置采样策略（即下图中的C），使系统在训练时更有效率。</h2><p><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517124548.png" alt="image-20210516150557725"></p>
<h2 id="A2：从3D图像处理方法进行借鉴"><a href="#A2：从3D图像处理方法进行借鉴" class="headerlink" title="A2：从3D图像处理方法进行借鉴"></a>A2：从3D图像处理方法进行借鉴</h2><p><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517124630.png" alt="image-20210515203300128"></p>
<p>论文指出，在规则网络上对2D图像的计算是住哟主要范式，但是这不是其他视觉任务的情况。在3D形状识别中，由于立方体的限制，难以实现大的3D网格。</p>
<p>最近的网络考虑到更多有效的非均匀表示，如网格[47,14]、符号距离函数[37]和八叉树[46]。与符号距离函数类似，PointRend可以计算任意点的分割值。</p>
<p>Occupancy Networks: Learning 3D Reconstruction in Function Space这篇论文就是PointRend提到的[37],下面是我在这篇论文中找到的相关的内容</p>
<p><img src= "/img/loading.gif" data-src="https://gitee.com/Black_Friday/blog/raw/master/image/20210517124638.png" alt="image-20210516143139932"></p>
<p>为了学习神经网络fθ(p,  x)的参数θ，我们<strong>在考虑的对象的三维边界体中随机抽样点</strong>:对于训练批中的第i个样本，我们抽样K个点pij∈R3, j = 1， . .。，  k，然后我们评估这些位置的小批量损失LB。</p>
<p><strong>我们可以看到，这篇论文中也只提到了一下在三维边界物体进行随机取样。（似乎并没有其他的解释，也许是我没有找到，或者这是一些我不知道的三维图像知识。求求相关理解或了解的大佬科普。）</strong></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>简而言之，PointRend使用一种非均匀的采样方式，在上采样的时候，对一些高频位置的点进行特殊处理，使结果更加精细。</p>
<p>灵感来源于：因为分割模型最难判断的点基本上都在物体边缘，而边缘只占了整个物体中非常小的一部分。所以作者提出可以每次在预测出来的mask中只选择Top N最不确定的点进行细分预测。目的是在提高分辨率后确定边界上的点，并对这些点进行归类。该方法可以合并到当前主流的分割架构中，如mask r-cnn和FCN，其subdivision策略使用的浮点计算比直接的密集计算要少一个数据量，可以有效的计算得到高分辨率的分割mask。</p>
<p>这种新型的上采样方式，将优化物体边缘的图像分割，适用于对难以分割的物体边缘，或是对边缘分割精度要求很高的场景下。 </p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Fly-Pluche</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://fly-pluche.github.io/posts/PointRend/">https://fly-pluche.github.io/posts/PointRend/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://Fly-Pluche.github.io" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://fly-pluche.github.io" target="_blank">Fly-Pluche</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/HCLonely/hclonely.github.io/img/Butterfly/014.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><button class="reward-button" type="button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.png" alt="wechat" onclick="window.open('/img/wechat.png')"/><div class="post-qr-code__desc">wechat</div></li><li class="reward-item"><img class="post-qr-code__img" src="/img/alipay.jpg" alt="alipay" onclick="window.open('/img/alipay.jpg')"/><div class="post-qr-code__desc">alipay</div></li><li class="reward-item"><img class="post-qr-code__img" src="/img/qq.png" alt="qq" onclick="window.open('/img/qq.png')"/><div class="post-qr-code__desc">qq</div></li></ul></div></button></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/Math/"><img class="prev-cover" data-src="https://cdn.jsdelivr.net/gh/HCLonely/hclonely.github.io/img/Butterfly/017.webp" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Math</div></div></a></div><div class="next-post pull-right"><a href="/posts/Image_high_and_low_frequency/"><img class="next-cover" data-src="https://cdn.jsdelivr.net/gh/HCLonely/hclonely.github.io/img/Butterfly/018.webp" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">图像高低频</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/posts/IoU_loss/" title="IoU loss"><img class="relatedPosts_cover" data-src="https://cdn.jsdelivr.net/gh/HCLonely/hclonely.github.io/img/Butterfly/013.webp"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-17</div><div class="relatedPosts_title">IoU loss</div></div></a></div><div class="relatedPosts_item"><a href="/posts/2020_Filter_Grafting/" title="2020_Filter Grafting"><img class="relatedPosts_cover" data-src="https://cdn.jsdelivr.net/gh/HCLonely/hclonely.github.io/img/Butterfly/009.webp"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-17</div><div class="relatedPosts_title">2020_Filter Grafting</div></div></a></div><div class="relatedPosts_item"><a href="/posts/CVPR2021_Coordinate_Attention/" title="CVPR2021_Coordinate_Attention注意力机制"><img class="relatedPosts_cover" data-src="https://cdn.jsdelivr.net/gh/HCLonely/hclonely.github.io/img/Butterfly/012.webp"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-17</div><div class="relatedPosts_title">CVPR2021_Coordinate_Attention注意力机制</div></div></a></div><div class="relatedPosts_item"><a href="/posts/2017_Slimming_pytorch/" title="2017_Slimming_pytorch"><img class="relatedPosts_cover" data-src="https://cdn.jsdelivr.net/gh/HCLonely/hclonely.github.io/img/Butterfly/010.webp"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-17</div><div class="relatedPosts_title">2017_Slimming_pytorch</div></div></a></div><div class="relatedPosts_item"><a href="/posts/canny_loss/" title="canny边缘loss"><img class="relatedPosts_cover" data-src="https://cdn.jsdelivr.net/gh/HCLonely/hclonely.github.io/img/Butterfly/011.webp"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-17</div><div class="relatedPosts_title">canny边缘loss</div></div></a></div><div class="relatedPosts_item"><a href="/posts/Englishwords/" title="阅读论文常见的英语单词"><img class="relatedPosts_cover" data-src="https://cdn.jsdelivr.net/gh/HCLonely/hclonely.github.io/img/Butterfly/008.webp"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-17</div><div class="relatedPosts_title">阅读论文常见的英语单词</div></div></a></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2021  <i id="heartbeat" class="fa fas fa-heartbeat"></i> Fly-Pluche</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="http://fly-pluche.github.io//">blog</a>!</div></div><head><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/HCLonely/images@master/others/heartbeat.min.css"><meta name="generator" content="Hexo 4.2.1"></head></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/calendar.js"></script><script src="/js/languages.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":120,"height":260},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>